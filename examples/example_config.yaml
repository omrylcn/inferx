# Example InferX Configuration
# This shows how to customize InferX for your specific use case

# ================================================================
# CUSTOM MODEL DETECTION
# ================================================================
# Add your custom model naming patterns
model_detection:
  yolo_keywords:
    - "yolo"
    - "yolov8"
    - "yolov11" 
    - "my_custom_yolo"        # Add your custom model names
    - "vehicle_detector"      # Example: vehicle detection model
  
  # Add custom classification model patterns
  classification_keywords:
    - "resnet"
    - "efficientnet"
    - "my_classifier"         # Your custom classifier
    - "emotion_detector"      # Example: emotion classification

# ================================================================
# DEVICE AND PERFORMANCE PREFERENCES
# ================================================================
# Customize device preferences for your hardware
device_mapping:
  auto: "GPU"                 # Prefer GPU when auto is selected
  my_device: "MYRIAD"        # Map custom device name to Myriad VPU

# Use high-throughput preset for batch processing
performance_presets:
  production:
    openvino:
      performance_hint: "THROUGHPUT"
      num_streams: 0           # Auto-detect optimal streams
      num_threads: 8           # Use 8 threads
    onnx:
      providers: ["CUDAExecutionProvider", "CPUExecutionProvider"]
      session_options:
        graph_optimization_level: "ORT_ENABLE_ALL"
        inter_op_num_threads: 8

# ================================================================
# CUSTOM MODEL SETTINGS
# ================================================================
model_defaults:
  # Custom YOLO settings for higher accuracy
  yolo:
    input_size: 1024           # Use higher resolution
    confidence_threshold: 0.3  # Lower threshold for more detections
    nms_threshold: 0.4         # Slightly lower NMS threshold
    
    # Custom class names for your specific model
    class_names:
      - "person"
      - "vehicle"
      - "bicycle"
      - "traffic_sign"
      - "traffic_light"
  
  # Custom classification settings
  classification:
    input_size: [384, 384]     # Higher resolution for better accuracy
    top_k: 3                   # Return top 3 predictions
    
    # Custom normalization for your model
    normalize:
      mean: [0.5, 0.5, 0.5]    # Different normalization
      std: [0.5, 0.5, 0.5]

# ================================================================
# LOGGING AND DEBUG SETTINGS
# ================================================================
logging:
  level: "INFO"               # Set to DEBUG for detailed logs
  categories:
    model_loading: true
    inference_timing: true
    preprocessing: false       # Enable for debugging preprocessing
    postprocessing: false      # Enable for debugging postprocessing
    device_info: true

# ================================================================
# OUTPUT CUSTOMIZATION
# ================================================================
output:
  default_format: "json"      # or "yaml"
  float_precision: 4          # Reduce precision to save space
  
  include_metadata:
    model_info: true
    timing_info: true
    device_info: false        # Disable to reduce output size
    config_used: false        # Enable to see what config was used

# ================================================================
# ADVANCED OPTIMIZATIONS
# ================================================================
advanced:
  # Enable model caching for faster startup
  model_cache:
    enabled: true
    cache_dir: "./model_cache"  # Local cache directory
    max_cache_size_gb: 10
  
  # Memory optimizations for large batch processing
  memory:
    enable_memory_pool: true
    max_memory_pool_size_mb: 2048
  
  # Experimental features (use with caution in production)
  experimental:
    enable_dynamic_batching: false
    enable_model_optimization: true    # Enable model optimization
    enable_mixed_precision: false